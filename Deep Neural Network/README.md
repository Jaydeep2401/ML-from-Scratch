## Deep Neural Network

This folder contains implementation of Deep Neural Network (with L layers defined by user) from scratch with its application for binary classification.

### Note

> Here we have designed architecture for binary classification, if required you can tweak the architecture for desired outcome.
> There are three activation functions implemented, which are, relu, tanh and sigmoid, if required you can add more and make changes wherever required.
> You will have to pass activations and number of hidden units for each layer in a list to model as shown in the notebook demonstrating how to use the class.

### Contributors:

- [Jaydeep](https://github.com/Jaydeep2401)
- [Aynaan](https://github.com/Aynaan)